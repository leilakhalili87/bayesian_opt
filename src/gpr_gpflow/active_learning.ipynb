{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A sample code to apply customized kernel using gpflow\n",
    "\n",
    "In this code GPR is applied to predict the enery of 388 grain boundaries of olmsted database.\n",
    "\n",
    "The pairwise distances are calculated based on the octonion package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from gpflow.utilities import print_summary, positive\n",
    "from gpflow.config import set_default_float, default_float, set_default_summary_fmt\n",
    "from gpflow.ci_utils import ci_niter\n",
    "\n",
    "set_default_float(np.float64)\n",
    "set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose input data\n",
    "- `N` number of all the gbs\n",
    "    - `N=388` for the olmsted database\n",
    "    - `N=297` for Dr. Patala's paper\n",
    "- `n_train` number of the gbs in the training datseet\n",
    "- `n_iter` number of the iterations in the active learning\n",
    "- `n_max` number of the gbs added to the training data set in each iteration. These gbs has the highest variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define database '297' or '388'\n",
    "N = 297\n",
    "\n",
    "# define numbe rof training dataset\n",
    "n_train = 10\n",
    "\n",
    "n_iter = 80\n",
    "\n",
    "n_max = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "if N == 297:\n",
    "    data_E = './data/297_energy.txt'\n",
    "    data_pd = './data/297_octonion_pd.txt'\n",
    "    data_axes = './data/sigma3_data.txt'\n",
    "    if n_train > N:\n",
    "        print('The numbe rof trainign datset should be smaller than 297')\n",
    "else:\n",
    "    data_E = './data/energy_olms.txt'\n",
    "    data_pd = './data/pd_olms.txt'\n",
    "    if n_train > N:\n",
    "        print('The numbe rof trainign datset should be smaller than 388')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta is in the range of:\n",
      "[-26.56505117707799, 45.0]\n",
      "\n",
      "phi is in the range of:\n",
      "[54.735610317245346, 135.0]\n"
     ]
    }
   ],
   "source": [
    "# a function to convert the data into spherical coordinates\n",
    "# this works for N = 297\n",
    "def ax2spher(ax):\n",
    "    # all the vectors are normalized so r=1\n",
    "    # theta is between 0, 2pi\n",
    "    theta = np.arctan(ax[1]/ax[0])*180/np.pi # angle with z axis\n",
    "    # phi is between 0 and pi\n",
    "    phi = np.arccos(ax[2])*180/np.pi # angle with x axis\n",
    "    return theta, phi\n",
    "\n",
    "if N == 297:  \n",
    "    data = np.loadtxt(data_axes)\n",
    "    axes = data[:,0:3]\n",
    "\n",
    "    n_axes = axes/np.linalg.norm(axes, axis=1, keepdims=True)\n",
    "    n_data = len(n_axes)\n",
    "    angles = np.zeros((n_data,2))\n",
    "    for i in range(n_data):\n",
    "        theta, phi = ax2spher(n_axes[i,:])\n",
    "        angles[i] = np.array([theta, phi])\n",
    "    print('Theta is in the range of:')\n",
    "    range_theta = [np.min(angles[:,0]), np.max(angles[:,0])]\n",
    "    print(range_theta)\n",
    "\n",
    "    print('\\nphi is in the range of:')\n",
    "    range_phi = [np.min(angles[:,1]), np.max(angles[:,1])]\n",
    "    print(range_phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I defined a new class for the our custom kernel named `GBKernel`. This kernel is inhereted from the `gpflow.kernels.Matern12`. Within this kernel the octonion distance is defined. The octonion distances are previously calculated using the Matlab code. In this function (`_octonion_dist`) the corresponding rows and vectors are extracted from the matlab output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBKernel(gpflow.kernels.Matern12):\n",
    "    \"\"\"\n",
    "    Isotropic RBF Kernel with Haversine distance instead of euclidean distance.\n",
    "    Assumes 2 dimensional data, with columns [latitude, longitude] in degrees.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lengthscales=1.0):\n",
    "        super().__init__(active_dims=[0])\n",
    "\n",
    "    def _octonion_dist(self, X, X2):\n",
    "        pd = np.loadtxt(data_pd)\n",
    "        xx = np.unique(np.concatenate((id_test, id_train), axis= 0)).reshape(-1,1)\n",
    "\n",
    "        len_x = len(xx)\n",
    "        dist = np.zeros((len_x, len_x))\n",
    "        for i in range(len_x):\n",
    "            for j in range(len_x):\n",
    "                dist[i,j] = pd[int(xx[i]), int(xx[j])]\n",
    "        return dist\n",
    "\n",
    "#     @params_as_tensors\n",
    "    def _scaled_square_dist(self, X, X2):\n",
    "        \"\"\"\n",
    "    The Matern 1/2 kernel. Functions drawn from a GP with this kernel are not\n",
    "    differentiable anywhere. The kernel equation is\n",
    "\n",
    "    k(r) = σ² exp{-r}\n",
    "\n",
    "    where:\n",
    "    r  is the Euclidean distance between the input points, scaled by the lengthscales parameter ℓ.\n",
    "    σ² is the variance parameter\n",
    "    \"\"\"\n",
    "        if X2 is None:\n",
    "            X2 = X\n",
    "#         dist = tf.square(self._haversine_dist(X, X2) / self.lengthscales)\n",
    "#         dist = self.variance * tf.exp(-0.5 * self._octonion_dist(X, X2))\n",
    "        dist = self.variance * tf.exp(-self._octonion_dist(X, X2))\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data are imported from the text file. Then `n_train` data is added as the training data set. The rest of the data is considered as the test dataset. \n",
    "\n",
    "The GPR model is created and optimized. Then in each iteration, in total `n_iter` iterations,  the `n_max` grain boundaries with the highest variance is added to the training data set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract the data for the first run\n",
    "Y_all = np.loadtxt(data_E)\n",
    "id_all = np.linspace(0,N-1, N)\n",
    "\n",
    "# I chose n_train gbs as training data set randomly\n",
    "id_train = np.sort(np.random.choice(N, size=n_train, replace=False))\n",
    "Y_train = Y_all[id_train].reshape(-1,1)\n",
    "id_train = np.array(id_train, dtype=np.float64)\n",
    "\n",
    "# I chose rest of the gbs as the test set\n",
    "id_test = id_all[~np.in1d(id_all,id_train)].reshape(-1,1)\n",
    "id_train = id_train.reshape(-1,1)\n",
    "m = gpflow.models.GPR((id_train, Y_train), kernel=GBKernel())\n",
    "\n",
    "opt = gpflow.optimizers.Scipy()\n",
    "opt.minimize(m.training_loss, variables=m.trainable_variables)\n",
    "\n",
    "mean, var = m.predict_y(id_test)\n",
    "\n",
    "var_np  = var.numpy().reshape(-1)\n",
    "new_gb_id = id_test[(-var_np).argsort()[:n_max]]\n",
    "\n",
    "\n",
    "for i in range(n_iter):\n",
    "    new = np.sort(new_gb_id).reshape(-1,1)\n",
    "    id_train = np.sort(np.concatenate((new, id_train))).reshape(-1,1)\n",
    "    Y_train = Y_all[id_train.astype(int)].reshape(-1,1)\n",
    "    all_d = id_all.astype(int)\n",
    "    train_d = id_train.astype(int)\n",
    "    id_test = id_all[~np.in1d(all_d,train_d)].reshape(-1,1)\n",
    "    id_test = np.array(id_test, dtype=np.float64)\n",
    "    m = gpflow.models.GPR((id_train, Y_train), kernel=GBKernel())\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "    opt.minimize(m.training_loss, variables=m.trainable_variables)\n",
    "\n",
    "    mean, var = m.predict_y(id_test)\n",
    "\n",
    "    var_np  = var.numpy().reshape(-1)\n",
    "    new_gb_id = id_test[(-var_np).argsort()[:n_max]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I plotted the results.\n",
    "\n",
    "If `N=297` the results can be plotted based on `theta` (`plot_pref` = `out_ang1`) or `phi` (`plot_pref` = `out_ang2`).\n",
    "\n",
    "If `N=388` the plot is based on the id of the gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pref = 'phi' # 'phi' or 'theta'\n",
    "\n",
    "    \n",
    "if N == 297:\n",
    "    \n",
    "    test_angle = np.zeros((len(id_test), 2))\n",
    "    train_angle = np.zeros((len(id_train), 2))\n",
    "    for i in range(len(id_test)):\n",
    "        test_angle[i] = angles[int(i)]\n",
    "    for i in range(len(id_train)):\n",
    "        train_angle[i] = angles[int(i)]\n",
    "    test_angle1 = test_angle[:,0].reshape(-1,1)\n",
    "    train_angle1 = train_angle[:,0].reshape(-1,1)\n",
    "\n",
    "    test_angle2 = test_angle[:,1].reshape(-1,1)\n",
    "    train_angle2 = train_angle[:,1].reshape(-1,1)\n",
    "\n",
    "    output_1 = np.stack([test_angle1, mean, var ], axis=0).reshape(3, len(test_angle1))\n",
    "    out_ang1 = output_1[:, np.argsort(output_1[0, :])]\n",
    "\n",
    "    output_2 = np.stack([test_angle2, mean, var ], axis=0).reshape(3, len(test_angle2))\n",
    "    out_ang2 = output_2[:, np.argsort(output_2[0, :])]\n",
    "    if plot_pref == 'phi':\n",
    "        plot_pref = out_ang2\n",
    "    else:\n",
    "        plot_pref = out_ang1\n",
    "\n",
    "    ## plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_angle2, Y_train, \"kx\", mew=2)\n",
    "    plt.plot(plot_pref[0,:], plot_pref[1,:], \"C0\", lw=2)\n",
    "    plt.fill_between(\n",
    "        plot_pref[0,:],\n",
    "        plot_pref[1, :] - 1.96 * np.sqrt(plot_pref[2,:]),\n",
    "        plot_pref[1,:] + 1.96 * np.sqrt(plot_pref[2,:]),\n",
    "        color=\"C0\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    plt.xlabel('angle')\n",
    "    plt.ylabel('energy')\n",
    "else:\n",
    "    ## plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(id_train, Y_train, \"kx\", mew=2)\n",
    "    plt.plot(id_test, mean, \"C0\", lw=2)\n",
    "    plt.fill_between(\n",
    "        id_test[:, 0],\n",
    "        mean[:, 0] - 1.96 * np.sqrt(var[:, 0]),\n",
    "        mean[:, 0] + 1.96 * np.sqrt(var[:, 0]),\n",
    "        color=\"C0\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    plt.xlabel('id of the grain boundary')\n",
    "    plt.ylabel('energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
